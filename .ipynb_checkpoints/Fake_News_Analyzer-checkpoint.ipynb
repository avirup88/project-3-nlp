{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24f1dd-f61a-4eb6-89cf-204647d1e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as px\n",
    "import nltk\n",
    "import os\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import FastText\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b597056-27de-40d1-9dc1-28a0e881d83b",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6247061-feb6-4166-bedc-452e4519f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training set\n",
    "training_df = pd.read_csv('./dataset/training_data.csv',sep='\\t', header=None)\n",
    "\n",
    "#Add meaningful column names\n",
    "training_df.columns = ['fake_news_flag','news_content']\n",
    "\n",
    "#Re-order the columns\n",
    "training_df = training_df[['news_content','fake_news_flag']]\n",
    "\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb9370-32a1-4a1f-b5f7-72bceadfa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of fake_news_flag\n",
    "value_counts = training_df['fake_news_flag'].value_counts()\n",
    "\n",
    "# Set the plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.barplot(x=value_counts.index, y=value_counts.values, palette=\"coolwarm\", hue=value_counts.index, legend=False)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for i, value in enumerate(value_counts.values):\n",
    "    plt.text(i, value + 0.5, str(value), ha='center', va='bottom', fontsize=15)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Fake News Flags', fontsize=16)\n",
    "plt.xlabel('News Label', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Customize tick labels\n",
    "plt.xticks(ticks=range(len(value_counts.index)), labels=[\"Fake\", \"Not Fake\"], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1151dff-fcad-4eb0-9c0a-07566ccef919",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c8ef2-3b30-4cfc-a753-86f420cf7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_clean_text(texts):\n",
    "    docs = nlp.pipe(texts)  # Batch processing\n",
    "    cleaned_texts = [\n",
    "        ' '.join([token.text for token in doc if token.is_alpha and not token.is_stop])\n",
    "        for doc in docs\n",
    "    ]\n",
    "    return cleaned_texts\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Convert the case to lower\n",
    "training_df['news_content'] = training_df['news_content'].str.lower()\n",
    "\n",
    "# Apply the cleaning function\n",
    "training_df['news_content_clean'] = fn_clean_text(training_df['news_content'])\n",
    "\n",
    "#Count the number of words in each news\n",
    "training_df['num_words'] = training_df['news_content_clean'].str.split(' ').str.len()\n",
    "\n",
    "# Display the result\n",
    "training_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d63a9c-cfd2-4fbe-947d-2ba97aea5a5c",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db744a6f-1340-43d9-8998-fb7f7a5987c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `training_df` has 'news_content_clean' and 'label' columns\n",
    "X = training_df['news_content_clean']\n",
    "y = training_df['fake_news_flag']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(X, y, training_df.index, test_size=0.3, random_state=42)\n",
    "print(\"Training Size : {}\".format(X_train.shape[0]))\n",
    "print(\"Test Size : {}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99798d0-a632-4ee2-954d-f23c4695f5d6",
   "metadata": {},
   "source": [
    "# Text Vectorization - Tf-Idf vs FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba69fd-834c-48ca-999a-e17bc53829d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000) \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c2855-c989-4f40-a434-1097e2b7cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize train and test sets separately to avoid leakage\n",
    "train_corpus = X_train.apply(str.split).tolist()\n",
    "test_corpus = X_test.apply(str.split).tolist()\n",
    "\n",
    "#Train FastText model on the training data only\n",
    "fasttext_model = FastText(sentences=train_corpus, vector_size=100, window=5, min_count=1, epochs=10)\n",
    "\n",
    "# Step 4: Create document embeddings\n",
    "def get_document_embedding_fasttext(doc, model):\n",
    "    \"\"\"\n",
    "    Generate a document embedding by averaging word vectors.\n",
    "    If a word is not in the model, it is ignored.\n",
    "    \"\"\"\n",
    "    word_vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.vector_size)\n",
    "\n",
    "# Transform train and test sets into embeddings\n",
    "X_train_embeddings = np.array([get_document_embedding_fasttext(doc, fasttext_model) for doc in train_corpus])\n",
    "X_test_embeddings = np.array([get_document_embedding_fasttext(doc, fasttext_model) for doc in test_corpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df59017-cf28-4f29-ab6e-6110b19e246f",
   "metadata": {},
   "source": [
    "# Different models test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7a51c0-e399-4426-b69d-9540a63c0ab8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae78ac-2779-4b19-9051-745d9e09007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with TF-IDF\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Random Forest with FastText Embeddings\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test_embeddings)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"FastText Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba4f63-b948-467e-bd08-d9628a3d5c79",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c09b9-b1a9-4f90-93fd-d61fe1568792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost with TF-IDF\n",
    "xgb = XGBClassifier(n_estimators=500, learning_rate = 0.1, random_state=42, reg_lambda=1)\n",
    "xgb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgb.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=500, learning_rate = 0.1, random_state=42, reg_lambda=1)\n",
    "xgb.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgb.predict(X_test_embeddings)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"FastText Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d6a30-472e-4fe0-8955-f688517044c9",
   "metadata": {},
   "source": [
    "## LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19440af4-9693-43a9-9a64-c3b8188531c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "    \n",
    "lgb = LGBMClassifier(n_estimators=500, learning_rate = 0.1, random_state=42, reg_lambda=1, verbose=0)\n",
    "lgb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lgb.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"TF_IDF Accuracy:\", accuracy)\n",
    "\n",
    "lgb = LGBMClassifier(n_estimators=500, learning_rate = 0.1, random_state=42, reg_lambda=1, verbose=0)\n",
    "lgb.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lgb.predict(X_test_embeddings)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"FastText Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b01d7-bafd-49c2-8dce-8a9236235ae5",
   "metadata": {},
   "source": [
    "# Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3811450-7dba-4406-884d-b4321760a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Tuned Classical Model\n",
    "xgb = XGBClassifier(n_estimators=500, \n",
    "                    learning_rate = 0.1,\n",
    "                    reg_lambda = 1,\n",
    "                    random_state=42)\n",
    "\n",
    "xgb.fit(X_train_embeddings, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = xgb.predict(X_test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b59cd-ae31-4288-b861-8d97ee087cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "class_labels = ['Fake News', 'Real News']\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be576e-306b-4def-8451-afe5233cf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the test set with predictions\n",
    "test_results = pd.DataFrame({\n",
    "    'original_index': idx_test,\n",
    "    'news_content': X_test,\n",
    "    'true_label': y_test,\n",
    "    'predicted_label': y_pred\n",
    "})\n",
    "\n",
    "test_results = test_results[['news_content','true_label','predicted_label']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e08e8d-46e6-4b12-8bbf-588dae27fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kind of emotions do fake news evoke?\n",
    "# What type of information is generally faked?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2b63f-e1a9-47ff-bc6c-3ee0f0fe6d94",
   "metadata": {},
   "source": [
    "# Hugging Face Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d76f04f-c693-4b1c-8875-c3a72ecd0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "MODEL = \"jaranohaal/distilbert-base-uncased-finetuned-fake-news\"\n",
    "clf = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29305d23-37a6-49c1-aa37-3db572b0e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict using pre-trained model\n",
    "y_pred = clf(X_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68760ac9-a5d8-4e16-b52c-69ea26a77bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataset\n",
    "predictions = pd.DataFrame(y_pred)\n",
    "predictions['predicted_label'] =  predictions['label'].apply(lambda x:int(x[-1]))\n",
    "predictions = predictions[['predicted_label','score']]\n",
    "\n",
    "\n",
    "#Merge the results\n",
    "test_results = pd.DataFrame({'news_content': X_test,\n",
    "                             'true_label': y_test}).reset_index(drop=True)\n",
    "\n",
    "test_results = pd.concat([test_results,predictions],axis=1)\n",
    "\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743f204-2388-47b9-baeb-a943574907c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_test = test_results['true_label']\n",
    "y_pred = test_results['predicted_label']\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "class_labels = ['Fake News', 'Real News']\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fa75f-17c1-485b-aecf-2178cc36147f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145ea63-a628-4c3e-8ead-76f3190ee55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_df = training_df['news_content_clean'][training_df['fake_news_flag'] == 0]\n",
    "fake_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe5f4f-319b-4c30-978a-fe3609ef5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f6f18-ad9e-4358-aa7a-1b53fd7f7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"cirimus/modernbert-large-go-emotions\", return_all_scores=True)\n",
    "\n",
    "sentences = [\"I am not having a great day\"]\n",
    "\n",
    "model_outputs = classifier(sentences)\n",
    "print(model_outputs[0])\n",
    "# produces a list of dicts for each of the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8079ff9-fde7-4913-be92-663193459119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
